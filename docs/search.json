[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "joshua loftus",
    "section": "",
    "text": "I’m a first-generation college graduate who went from homeschooling, to community college, and eventually to finishing a PhD in Statistics at Stanford University. I’m grateful for the opportunities and to the teachers who helped me along the way. Diversity, inclusion, and mentoring are part of my identity. In my teaching I want to empower students to use the powerful tools of data science for good.\nMy research focuses on practices in machine learning and data science pipelines with the goal of correcting biases that are often overlooked. Some key applications include finding and repairing the causes of the replication crisis in science and socially harmful applications of machine learning and artificial intelligence. My peer reviewed research has been published in the Annals of Statistics, Biometrika, Advances in Neural Information Processing Systems (NeurIPS), and the International Conference on Machine Learning (ICML)."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "joshua loftus",
    "section": "Education",
    "text": "Education\n\nPh.D. Statistics, (Biostatistics trainee), Stanford University, 2016.\nM.A. Mathematics, (concentration in computational biology), Rutgers University, 2011.\nB.S. Mathematics, (summa cum laude), Western Michigan University, 2009.\nA.A. Kalamazoo Valley Community College, 2007."
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "joshua loftus",
    "section": "Experience",
    "text": "Experience\n\nAssistant Professor, London School of Economics, Department of Statistics, and Affiliate of the Data Science Institute, 2021-present.\nAssistant Professor, New York University, Department of Technology, Operations, and Statistics, and Affiliate of the Center for Data Science, 2017-2020.\nResearch Fellow, Alan Turing Institute and University of Cambridge, 2016-17.\n\n\nThe meaning of “Neurath’s Speedboat”\n“We are like sailors who on the open sea must reconstruct their ship” while traveling at 90mph"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "{{< fa solid chart-simple size=large >}} joshua loftus",
    "section": "",
    "text": "Random wanderer from the United States, professor of Statistics and Data Science at LSE.\nI think technology, institutions, and ideas should serve people, but much of humanity is stuck with this upside-down. How can we change that?"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "neurath’s speedboat",
    "section": "",
    "text": "statistics\n\n\nmachine learning\n\n\nphysics\n\n\n\n\nPhysics intuition for regression and other methods that minimize squared error. We can imagine springs pulling the model toward the data.\n\n\n\n\n\n\nFeb 16, 2022\n\n\nJoshua Loftus\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nSome retrospective on an eventful 2020, announcing a move from New York to London, a couple book recommendations, and a new design for this website.\n\n\n\n\n\n\nDec 21, 2020\n\n\nJoshua Loftus\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nstatistics\n\n\nreproducibility\n\n\n\n\nRecent arguments against the use of p-values and significance testing are mostly weak. The weak ones are actually arguments against making decisions or mistakes in general, which is impossible.\n\n\n\n\n\n\nNov 18, 2019\n\n\nJoshua Loftus\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nstatistics\n\n\nreproducibility\n\n\nselective inference\n\n\nR\n\n\n\n\nModel selection can invalidate inference, such as significance tests, but statisticians have recently made progress developing methods to adjust for this bias. This post motivates a conditional approach with a simple screening rule example and introduces an R package that can compute adjusted significance tests.\n\n\n\n\n\n\nFeb 26, 2018\n\n\nJoshua Loftus\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstatistics\n\n\nreproducibility\n\n\n\n\nPeople often do regression model selection, either by hand or using algorithms like forward stepwise or the lasso. Sometimes they also report significance tests for the variables in the chosen model. But there’s a problem: the reason for p-value significance may just be something called model selection bias.\n\n\n\n\n\n\nFeb 13, 2018\n\n\nJoshua Loftus\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2020-11-23-least-squares-as-springs/least-squares-as-springs.html",
    "href": "posts/2020-11-23-least-squares-as-springs/least-squares-as-springs.html",
    "title": "Least squares as springs",
    "section": "",
    "text": "During a recent “Zoom” lecture a student asked me a question about outliers. In the process of answering I realized something that I knew was true but had never seen explained in any sources. This post is my first attempt to develop an analogy that connects least squares methods, like regression or PCA, to physical intuition about springs or elastics."
  },
  {
    "objectID": "posts/2020-11-23-least-squares-as-springs/least-squares-as-springs.html#the-simplest-version",
    "href": "posts/2020-11-23-least-squares-as-springs/least-squares-as-springs.html#the-simplest-version",
    "title": "Least squares as springs",
    "section": "The simplest version",
    "text": "The simplest version\nTo illustrate I will use data from gapminder conveniently provided in an R package by Jenny Bryan. Consider these two variables in the dataset, GDP per capita and life expectancy, plotted here in a standard scatterplot:\n\n\n\n\n\n(To have a less busy plot, one with fewer points, I’ve subsetted the data to the year 2007 and countries in Asia).\nNow we’re going to bring physical intuition into this by imagining these points as physical objects. For example, we can interpret the mean \\((\\bar x, \\bar y)\\) = 6252.7, 70.7 as the center of mass (if we assume every point has the same mass). This is the larger, blue point in the plot above. It’s not really important to think of mass specifically, just that this point is the center of the physical ensemble.\nWe need a few simple rules for our physical system:\n\nChanging the data is not allowed, i.e. the points are immovable.\nFor methods like regression (or PCA), we imagine a rigid object like a line (or hyperplane, in multiple regression) passing through the points, and the points exerting some force that changes the position of this body\nIf these methods use the standard least squares loss function then this force can be represented by springs or elastics, all of the same length and strength, attached at one end to the points and on the other end to the line (or hyperplane).\n\nThis line (or hyperplane) may bounce around at first as the springs pull it toward their anchoring points, but eventually it settles into an equilibrium where the forces from all the opposing springs are balanced out. In this equilibrium state we have two immediate consequences:\n\nThe rigid object (line or hyperplane) must pass through the center point. If it did not, there would be a net force acting on the object pulling it toward the center point, hence it would not yet be at equilibrium. In other words, all of the forces that would shift the object are exactly balanced out so it does not shift.\nThe same is true about torques, all of the forces that would rotate the object are balanced out.\n\nFor regression we need one more rule: the springs are guided so they only pull in directions aligned with the axis of the outcome variable, i.e. “vertically.” Let’s call this the vertical rule for reference later.\nHere is our simple example in picture form:\n\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\n(To create this plot I have copied the geom_spring example by Thomas Lin Pedersen from (the new version of!) the ggplot2 book).\nIf you are not immediately convinced that this intuition pays off, consider the issue that motivated me to think of this in the first place: influential outliers, points with high “leverage” in the statistical sense. The definition of statistical leverage is a bit complicated. But we can get the right intuition about it from a physical sense rather than those formal definitions. See the point in the bottom left of the plot above? Since it is pulling closer to the end of the line it has more leverage in the actual physical sense. This is the explanation I prefer to give students who aren’t taking a mathematical statistics course.\n(In case you’re wondering, that point is Afghanistan, a nation where the United States remains at war for almost two decades now…)\nLet’s see what happens when we move this one point so its leverage is being used to rotate the line clockwise instead of counter-clockwise. The old regression line, before this change, is shown as a faded line below for comparison.\n\n\n`geom_smooth()` using formula 'y ~ x'\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\nNotice the following changes: the center of mass has shifted a little, the point we moved is now a greater distance from the line so its force is larger, and the line has rotated noticeably due to the influence of this one point, even though our dataset has over 30 points, because that point has a lot of leverage.\n\nHooke’s law\nIs this intuition correct? Can we really think of least squares solutions (e.g. regression lines) as the equilibrium of a system of springs? Yes, or elastic rubber bands, or any material with linear elasticity, i.e. that follows Hooke’s law. Let’s consider how to apply this to regression, where for each point \\((x_i, y_i)\\) in the data, the spring attaches to the regression line at the point \\((x_i, \\hat y_i)\\). So the spring is stretched to a length of \\(|r_i| = |y_i - \\hat y_i|\\), and Hooke’s law says each spring is pulling on the line with a force proportional to this distance.\nWhen the system of the line and springs has stopped moving and settled into an equilibrium, this equilibrium position minimizes the energy of the system, which in this case is just the potential energy. The potential energy stored in a spring that is stretched a certain distance is the integral of the force over that distance, and since the force scales with the distance this means the energy scales with the squared distance. Hence, the equilibrium of this physical system minimizes the total potential energy:\n\\[\n\\sum_{i=1}^n \\frac{1}{2}k |r_i|^2 = \\frac{1}{2}k \\sum_{i=1}^n  (y_i - \\hat y_i)^2\n\\] where \\(k > 0\\) is the spring “stiffness” constant. The line that minimizes this is the same as the least squares regression line because the constants in front don’t change the minimizer. This argument works just as well for multiple regression as simple regression, even if we can’t visualize the higher dimensional plots involved. We can still think of springs that are pulling, perpendicular to the \\(y\\)-axis, on a hyperplane. In this case there can be torques in various different hyperplanes passing through the center of mass but they’re all balanced out, so the hyperplane doesn’t get “tilted” in any direction (if it’s in equilibrium)."
  },
  {
    "objectID": "posts/2020-11-23-least-squares-as-springs/least-squares-as-springs.html#principal-components-analysis",
    "href": "posts/2020-11-23-least-squares-as-springs/least-squares-as-springs.html#principal-components-analysis",
    "title": "Least squares as springs",
    "section": "Principal components analysis",
    "text": "Principal components analysis\nAlthough PCA is often considered a more advanced topic than (simple) regression, its justification in our physical analogy is actually simpler. All we need to do is drop the vertical rule that was required for regression. In this case, the springs are allowed to rotate their angle of departure from the points, and their position of attachment to the line (or hyperplane) can slide to accommodate this change in angle. This results in an equilibrium where the springs are stretched as little possible. The total potential energy reaches a lower value because the springs are no longer constrained in which direction they can pull.\n\n\n\n\n\nI’ve plotted the line in a different color to emphasize that it’s not the regression line. Notice that the springs are no longer pulling vertically, instead they connect to the line at the point on the line which is nearest (as measured by overall distance, not just distance in the \\(y\\)-coordinate alone).\n(This is also called total least squares or a special case of Deming regression.)"
  },
  {
    "objectID": "posts/2020-11-23-least-squares-as-springs/least-squares-as-springs.html#model-complexityelasticity-machine-learning-or-ai",
    "href": "posts/2020-11-23-least-squares-as-springs/least-squares-as-springs.html#model-complexityelasticity-machine-learning-or-ai",
    "title": "Least squares as springs",
    "section": "Model complexity/elasticity: machine learning or AI",
    "text": "Model complexity/elasticity: machine learning or AI\nWe can keep building on this analogy by using it to understand more complex modeling methods with another very simple idea: elasticity of the model object itself. Instead of a rigid body like a line (or hyperplane), if we imagine it’s made of an elastic material that can be (locally) stretched and deformed then we can get more complex types of regression models.\nIn this analogy, simpler models like linear regression correspond to more rigid objects like an unbendable metal stick, and more complex models allow flexibility or elasticity when fitting the conditional expectation function like a bendable plastic stick, a rubber band, or even a tensionless string in the most complex case where the model is allowed to fit the points perfectly.\nFor example, here’s the local polynomial regression method (loess) used by default in the ggplot function stat_smooth:\n\n\n\n\n\nThis intuition is not only useful for learning the basic ideas of model complexity and machine learning, it can even be used for cutting-edge research. For example see this recent paper on elasticity in neural networks (by my friend Weijie Su and his coauthor!)"
  },
  {
    "objectID": "posts/2020-11-23-least-squares-as-springs/least-squares-as-springs.html#concluding-thoughts",
    "href": "posts/2020-11-23-least-squares-as-springs/least-squares-as-springs.html#concluding-thoughts",
    "title": "Least squares as springs",
    "section": "Concluding thoughts",
    "text": "Concluding thoughts\nI think there’s a lot of potential here for statistics education, especially for younger students. It wouldn’t be too difficult to create a physical classroom demonstration using springs or elastics, especially for the PCA case since that wouldn’t require any guiding tracks to constraint the force direction to be vertical.\nI also need to teach myself some more advanced plotting to gganimate these examples. If I succeed I’ll update this page."
  },
  {
    "objectID": "posts/2020-11-23-least-squares-as-springs/least-squares-as-springs.html#references",
    "href": "posts/2020-11-23-least-squares-as-springs/least-squares-as-springs.html#references",
    "title": "Least squares as springs",
    "section": "References",
    "text": "References\nI was surprised by how difficult it was to find any references for this elementary idea that provides physical intuition for such an important method as least squares regression. If you’re aware of any others please contact me because I would be glad to know of them.\n(Update) Thankfully, after this post was shared widely on Twitter people have helped alert me to more references which are now included in the list below.\n\nDwight, T. W. (1937). The fitting of linear regression lines by the method of least squares. The Forestry Chronicle, 13(4), 509-519.\nLevi, M. (2012). The mathematical mechanic: using physical reasoning to solve problems. Princeton University Press.\nExcerpt of the previous reference on stackexchange\n\nUpdate: Thanks to everyone who has contacted me with these additional references!\n\nTrey Goesh created this interactive simulation\nKieran Healy linked to this stackexchange answer with an awesome animation\nKameron Decker Harris pointed out this blog post showing splines as bendy physical sticks\nChris Schwarz at UIowa brought my attention to these lectures by the legendary Gil Strang\nMichael Friendly created a bibliography of some references to physics inspired stats models\nA lecture by Yann LeCun in the NYU deep learning course\nA recent ICLR paper (with video of a short talk) by Will Grathwohl and others\nA paper on deep learning by Jascha Sohl-Dickstein and others\nJohn Davis at UIndiana created this demo showing 3D splines (just imagine the vertical lines are springs!) and pointed to a different physics-inspired example by Gavin Simpson"
  },
  {
    "objectID": "posts/2020-12-21-concise-defense-of-statistical-significance/concise-defense-of-statistical-significance.html",
    "href": "posts/2020-12-21-concise-defense-of-statistical-significance/concise-defense-of-statistical-significance.html",
    "title": "A concise defense of statistical significance",
    "section": "",
    "text": "A letter, signed by over 800 scientists and published in Nature called for an end to using p-values to decide whether data refutes or supports a scientific hypothesis. The letter has received widespread coverage and reignited an old debate."
  },
  {
    "objectID": "posts/2020-12-21-concise-defense-of-statistical-significance/concise-defense-of-statistical-significance.html#weaker-arguments",
    "href": "posts/2020-12-21-concise-defense-of-statistical-significance/concise-defense-of-statistical-significance.html#weaker-arguments",
    "title": "A concise defense of statistical significance",
    "section": "Weaker arguments",
    "text": "Weaker arguments\nMost of the objections to p-values or the p < 0.05 threshold in these articles can be summarized into two categories:\n\nObjections that would apply to any method resulting in a yes/no decision\nObjections that would apply to any method with yes/no decisions that might be wrong\n\n\nA histogram of z-scores showing apparent publication bias from Erik van Zwet and Eric Cator’s “significance filter” paper\n\n\n\n\n\n\nBanning p-values or “p < 0.05” thresholds wouldn’t address these objections. We will still have to make decisions, we can’t just report a Bayes factor (or a p-value) and refuse to decide whether a drug trial should continue or not. So our decisions will still sometimes be wrong, and in both directions."
  },
  {
    "objectID": "posts/2020-12-21-concise-defense-of-statistical-significance/concise-defense-of-statistical-significance.html#stronger-arguments",
    "href": "posts/2020-12-21-concise-defense-of-statistical-significance/concise-defense-of-statistical-significance.html#stronger-arguments",
    "title": "A concise defense of statistical significance",
    "section": "Stronger arguments",
    "text": "Stronger arguments\nThe last kind of objection is more sensible–though less often the focal point of this debate–and I would summarize it as:\n\nStatistical significance is not sufficient for practical significance, we need to know something about the effect size.\n\nI more or less agree with this, but it is not an objection to using p-values or p < 0.05, it’s an objection to misusing them or using them in isolation.\nAnd any method can be misused! A scientist could do many tests and only report the significant results, or they could compute many effect size estimates or Bayes factors and only report the largest ones."
  },
  {
    "objectID": "posts/2020-12-21-concise-defense-of-statistical-significance/concise-defense-of-statistical-significance.html#real-roots-of-the-problem",
    "href": "posts/2020-12-21-concise-defense-of-statistical-significance/concise-defense-of-statistical-significance.html#real-roots-of-the-problem",
    "title": "A concise defense of statistical significance",
    "section": "Real roots of the problem",
    "text": "Real roots of the problem\nI think there are two underlying problems that the p-value debate is mostly a distraction from: the rote, uncritical application of any kind of statistical method (because, as Jack Schwartz put it, “… the simple-mindedness … to dress scientific brilliancies and scientific absurdities alike in the impressive uniform of formulae and theorems. Unfortunately however, an absurdity in uniform is far more persuasive than an absurdity unclad.”), and the incentive structure of scientific publication.\nFrom Why most published research findings are false (Ioannidis):\n\nCorollary 4: The greater the flexibility in designs, definitions, outcomes, and analytical modes in a scientific field, the less likely the research findings are to be true.\nCorollary 5: The greater the financial and other interests and prejudices in a scientific field, the less likely the research findings are to be true.\nCorollary 6: The hotter a scientific field (with more scientific teams involved), the less likely the research findings are to be true."
  },
  {
    "objectID": "posts/2020-12-21-concise-defense-of-statistical-significance/concise-defense-of-statistical-significance.html#the-burden-of-the-burden-of-proof",
    "href": "posts/2020-12-21-concise-defense-of-statistical-significance/concise-defense-of-statistical-significance.html#the-burden-of-the-burden-of-proof",
    "title": "A concise defense of statistical significance",
    "section": "The burden of the burden of proof",
    "text": "The burden of the burden of proof\nLastly, it’s unfortunate but amusing that the Herald article mentioned many people misunderstand p-values, and the New Yorker article had this correction: “An earlier version of this article incorrectly defined p-value.”\nI sympathize with researchers who have done good work but can’t get it published because the result isn’t “significant.” This is a problem with publication standards, not statistical methods. It should be normal to publish negative or unimpressive results, otherwise the literature has little to teach us about what doesn’t work.\nIt’s also a resource issue. Collecting data is costly. There are many barriers to research other than arbitrary publication standards involving p-values, including many other arbitrary publication standards. While discontent has been focused on p-values, we may find ourselves suddenly facing de facto expectations of applying (often unnecessary) “artificial intelligence” to massive datasets in order to be published.\nNo particular statistical methodology is the cause or solution of these issues. (More and better statistics education is necessary!)"
  },
  {
    "objectID": "posts/2020-12-22-a-conditional-approach-to-inference-after-model-selection/a-conditional-approach-to-inference-after-model-selection.html",
    "href": "posts/2020-12-22-a-conditional-approach-to-inference-after-model-selection/a-conditional-approach-to-inference-after-model-selection.html",
    "title": "A conditional approach to inference after model selection",
    "section": "",
    "text": "A high profile case of a scientist retracting multiple papers due to p-hacking is recently gaining new attention due to a BuzzFeed article. Hopefully this will raise awareness and convince some that “keep hammering away at your data until you find want you were expecting” is a poor way to do science. But it’s possible to get things wrong, for the same reason, no matter how well-intentioned we may be. Even if we aren’t specifically seeking significant \\(p\\)-values, we can end up with biased results due to model selection. To see why, check out this earlier post on model selection bias. In this post I will describe a method to protect ourselves from this bias and compute adjusted \\(p\\)-values that are valid even though we’ve done model selection."
  },
  {
    "objectID": "posts/2020-12-22-a-conditional-approach-to-inference-after-model-selection/a-conditional-approach-to-inference-after-model-selection.html#model-selection-with-forward-stepwise",
    "href": "posts/2020-12-22-a-conditional-approach-to-inference-after-model-selection/a-conditional-approach-to-inference-after-model-selection.html#model-selection-with-forward-stepwise",
    "title": "A conditional approach to inference after model selection",
    "section": "Model selection with forward stepwise",
    "text": "Model selection with forward stepwise\nWe’ll pick up on the same example from a previous post:\n\n[…] consider the candy_rankings data from the fivethirtyeight package. The outcome variable is how often a given candy won in popularity matchups against other candies, and the predictor variables are various properties like whether or not the candy has chocolate, whether or not it’s fruit flavored, how sugary it is relative to other candies, and so on. There are 85 candies and 11 predictor variables in the dataset.\n\nThis time we’ll use the actual response variable, and run forward stepwise with AIC to pick a subset of the predictors that are highly predictive of the outcome (win percent). The resulting model, along with the biased \\(p\\)-values that popular software computes by default, is given below.\n\n\n                     Estimate Std. Error t value  Pr(>|t|)\nchocolateTRUE            19.1        3.6     5.3 0.0000009\nfruityTRUE                8.9        3.6     2.5 0.0147319\npeanutyalmondyTRUE        9.5        3.4     2.8 0.0073720\ncrispedricewaferTRUE      8.4        4.5     1.9 0.0652527\nhardTRUE                 -5.7        3.3    -1.7 0.0887116\nsugarpercent              8.0        4.1     1.9 0.0569311\n\n\nThese \\(p\\)-values are probably too small. The model selection method chose variables that seemed to be predictive of the outcome. The way \\(p\\)-values are computed is to consider how extreme the test statistic \\(T\\) is under the null hypothesis: \\(P(T > |t|)\\). But the model selection procedure picks variables that tend to have large observed values of \\(|t|\\), whether or not the null hypothesis for any one of them is true. How can we correct this? By the end of this post we’ll have adjusted \\(p\\)-values for this example, but first we need to understand how that adjustment works."
  },
  {
    "objectID": "posts/2020-12-22-a-conditional-approach-to-inference-after-model-selection/a-conditional-approach-to-inference-after-model-selection.html#adjusted-inference-by-conditionional-probability",
    "href": "posts/2020-12-22-a-conditional-approach-to-inference-after-model-selection/a-conditional-approach-to-inference-after-model-selection.html#adjusted-inference-by-conditionional-probability",
    "title": "A conditional approach to inference after model selection",
    "section": "Adjusted inference by conditionional probability",
    "text": "Adjusted inference by conditionional probability\nOne approach, often referred to as selective inference, is to use conditional probabilities when computing \\(p\\)-values. Consider a random variable \\(M\\) representing which model is chosen by the model selection method, and let \\(m\\) be the observed value of \\(M\\) after running the algorithm (e.g. forward stepwise) on our data and getting a specific model. To compute conditionally adjusted \\(p\\)-values, we use \\[\nP(T > |t| \\mid M = m)\n\\] This conditional probability law usually has a simple form. For example, if the test statistic has a \\(t\\)-distribution, then the conditional law is usually a truncated \\(t\\). The specifics depend on the kind of model selection algorithm being used, and working them out is an area of ongoing research in statistics. During my PhD, I worked on a few cases (groups of variables, cross-validation) as part of my dissertation. To understand how/why the conditional law works, let’s consider an example that’s simpler than forward stepwise."
  },
  {
    "objectID": "posts/2020-12-22-a-conditional-approach-to-inference-after-model-selection/a-conditional-approach-to-inference-after-model-selection.html#marginal-screening-example",
    "href": "posts/2020-12-22-a-conditional-approach-to-inference-after-model-selection/a-conditional-approach-to-inference-after-model-selection.html#marginal-screening-example",
    "title": "A conditional approach to inference after model selection",
    "section": "Marginal screening example",
    "text": "Marginal screening example\nSuppose that instead of regression, we are solving a many-means problem where we want to select the largest effects. (Regression is similar to this when the design matrix is orthogonal). That is, we have many effects \\(z_i\\) for \\(i = 1, \\ldots, p\\) and the selection rule we use is to choose \\(z_i\\) if \\(z_i > 1\\). Then we want to do a one-sided test to see if those \\(z_i\\) are significantly large. We can think of this procedure as first screening away the majority of the data which we think is just noise, and then testing what made it through the screening procedure. I’ll generate data under the global null hypothesis where every effect is actually zero, and then plot some results.\n\n\nWarning: Removed 2 rows containing missing values (geom_bar).\n\n\n\n\n\nThis plot shows three things:\n\nA histogram of the selected effects.\nThe solid line shows the standard normal distribution. The upper tail areas of this distribution would be used for standard, unadjusted \\(p\\)-values.\nThe dashed line shows the truncated, conditional distribution \\(Z | Z > 1\\) for a standard normal \\(Z\\).\n\nIf we used the tail areas of the standard normal to compute \\(p\\)-values, these would be very small, even though the data was all generated under a global null hypothesis. This shows that the selection effect can invalidate inference, leading to a high type 1 error rate. But it’s pretty clear from the plot that the conditional distribution fits the data very well: if “significant” means extreme according to this distribution, then type 1 error rate would be small, it would match whatever nominal threshold \\(\\alpha\\) we decided."
  },
  {
    "objectID": "posts/2020-12-22-a-conditional-approach-to-inference-after-model-selection/a-conditional-approach-to-inference-after-model-selection.html#the-selectiveinference-r-package",
    "href": "posts/2020-12-22-a-conditional-approach-to-inference-after-model-selection/a-conditional-approach-to-inference-after-model-selection.html#the-selectiveinference-r-package",
    "title": "A conditional approach to inference after model selection",
    "section": "The selectiveInference R package",
    "text": "The selectiveInference R package\nLet’s return to our first example about forward stepwise.\nThe details for computing \\(p\\)-values with conditional probability when model selection is more complicated–like using forward stepwise with AIC, or the LASSO with cross-validation, etc–are harder than the marginal screening case. But fortunately, there is an R package for it: the selectiveInference package available on CRAN! This package is still under development, and its authors include Ryan Tibshirani, Rob Tibshirani, Jonathan Taylor, Stephen Reid and some other guy. The package currently does not support R formulas, so first we need to create a model.matrix, then we’ll run forward stepwise again with the fs function, then we’ll compute adjusted inference for the fitted model using fsInf. These last two functions are among several others in the selectiveInference package, including ones for doing all of this with the LASSO instead of forward stepwise.\n\n\n\nCall:\nfsInf(obj = fit, type = \"aic\", ntimes = 1)\n\nStandard deviation of noise (specified or estimated) sigma = 10.703\n\nTesting results at step = 6, with alpha = 0.100\n Var   Coef Z-score P-value LowConfPt UpConfPt LowTailArea UpTailArea\n   1 19.147   5.233   0.171   -14.225   37.970        0.05      0.050\n   4  9.483   2.697   0.559   -43.440   13.021        0.05      0.049\n   2  8.881   2.445   0.472   -35.763   26.424        0.05      0.050\n   6  8.385   1.833   0.515   -61.565   46.348        0.05      0.050\n  10  7.979   1.894   0.355   -44.222   72.414        0.05      0.050\n   7 -5.669  -1.690   0.358   -48.097   30.090        0.05      0.050\n\nEstimated stopping point from AIC rule = 6\n\n\nThere’s a lot of output here, but let’s focus on the adjusted \\(p\\)-values. We’ll put them together in a readout with the unadjusted ones:\n\n\n                     Estimate    Pr(>|t|) Adj.Pr(>|t|)\nchocolateTRUE           19.15 0.000000898        0.171\npeanutyalmondyTRUE       9.48 0.007372014        0.559\nfruityTRUE               8.88 0.014731896        0.472\ncrispedricewaferTRUE     8.39 0.065252715        0.515\nsugarpercent             7.98 0.056931100        0.355\nhardTRUE                -5.67 0.088711566        0.358\n\n\nThe adjusted \\(p\\)-values in the right column are all much larger than the unadjusted ones. In general, adjusted \\(p\\)-values will be larger, but by how much depends on a lot of specifics. In this case, and at the usual \\(\\alpha = 0.05\\) level, we went from 3 significant effects without adjusting for selection bias to zero. This reflects a fundamental tradeoff: the more we use the data to search for interesting things, the less surprised we must be about what we find. Otherwise, we may just be fooling ourselves, and maybe even end up needing to retract lots of papers…\nI hope this post was a useful introduction to the basic idea of using conditional probability to adjust for model selection, and makes more people aware of the selectiveInference package. This project is also on github. In future posts I will describe more examples, including other approaches to adjusting inference for model selection bias."
  },
  {
    "objectID": "posts/2020-12-22-model-selection-bias-invalidates-significance-tests/model-selection-bias-invalidates-significance-tests.html",
    "href": "posts/2020-12-22-model-selection-bias-invalidates-significance-tests/model-selection-bias-invalidates-significance-tests.html",
    "title": "Model selection bias invalidates significance tests",
    "section": "",
    "text": "Significance testing may be one of the most popular statistical tools in science. Researchers and journals often treat significance–having a \\(p\\)-value \\(< 0.05\\)–as indication that a finding is true and perhaps publishable. But the tests used to compute many of the \\(p\\)-values people still rely on today were developed over a century ago, when “computer” was still a job title. Now that we have digital computers and it’s standard practice to collect and analyze “big data,” the mathematical assumptions underlying many classical significance tests are being pushed beyond their limits.\nThe journal Nature surveyed 1,576 scientists, asking them whether there is a reproducibility crisis, and found about 90% agreed. Across a range of disciplines, over 40% of respondents had tried and failed to reproduce at least one of their own experiments. What’s going on?\nAndrew Gelman suggested an analogy to describe how data analysis often proceeds in practice: the garden of forking paths. Researchers have to make many choices, and each choice represents a turn down a new fork in the path. Out of the many possible paths, how many end in significant, publishable findings, and how many in dead ends? Nobody wants to just give up when they reach a dead end, so maybe they retrace some of their steps and try a different path.\nModel selection might be the most labyrinthine part of this garden."
  },
  {
    "objectID": "posts/2020-12-22-model-selection-bias-invalidates-significance-tests/model-selection-bias-invalidates-significance-tests.html#what-is-model-selection-bias",
    "href": "posts/2020-12-22-model-selection-bias-invalidates-significance-tests/model-selection-bias-invalidates-significance-tests.html#what-is-model-selection-bias",
    "title": "Model selection bias invalidates significance tests",
    "section": "What is model selection bias?",
    "text": "What is model selection bias?\nTo illustrate with an example, we’ll consider the candy_rankings data from the fivethirtyeight package. The outcome variable is how often a given candy won in popularity matchups against other candies, and the predictor variables are various properties like whether or not the candy has chocolate, whether or not it’s fruit flavored, how sugary it is relative to other candies, and so on. There are 85 candies and 11 predictor variables in the dataset.\nYou can read the original article about this data here. In the article, they find that chocolate seems to be the most important variable for increasing the win percentage for a candy. We’ll approach the problem a little differently, and use model selection to pick a subset of the 11 predictor variables. Then we’ll report significance tests for the selected variables to show they really are important. This is a fairly common sequence of steps for analyzing data in linear regression.\n\nDetails for the curious: this particular method is a “greedy” algorithm that adds one predictor variable at a time into the model starting with the variable that has the highest correlation with the outcome, and stopping after choosing the number of variables in a data-driven way. These details are not important for the overall message of this post. Any model selection method can cause selection bias.\n\n\n\n             Estimate Std. Error t value Pr(>|t|)\n(Intercept)     -0.19       0.19    -1.0    0.309\ncaramelTRUE     -0.54       0.26    -2.1    0.042\nsugarpercent     0.79       0.35     2.3    0.026\n\n\nAs you can see, the model selection algorithm chose a nice interpretable model with only a few variables, and the small \\(p\\)-values for significance tests tell us they are truly important and our model is good…\nExcept none of this is true! The reason I didn’t show the code for loading the dataset earlier is that I created the outcome variable with Y = rnorm(n) (this function in R generates \\(n\\) random numbers following the normal distribution). Instead of using the actual outcome variable from the data, I generated a random normal variable, totally independent of the predictors. And yet, we found a model with predictor variables that are significant.\n\nA small simulation study\nLet’s think about this to get some intuition. If we have one predictor variable \\(X_1\\) and we generate \\(Y\\) from rnorm(n), then the correlation (in absolute value) between \\(X_1\\) and \\(Y\\) will probably be small. Let’s do this many times and look at the distribution of (absolute) observed correlations:\n\n\n\n\n\nThese correlations are pretty small. The bulk of the distribution is less than 0.1. We probably wouldn’t mistake them for signal. But now, what if we have more predictor variables, and we select the best (absolute) correlation each time?\n\n\n\n\n\nWhen we have 11 predictor variables and we select the one with the largest correlation, the resulting distribution of correlations is larger. The bulk is now centered around 0.2. We might mistake these larger correlations for signal, when in fact they only reflect the fact that we searched through the garden of forking paths and chose the most impressive path out of 11. Can you imagine how much worse this problem would be if instead of 11 variables we had 100 to choose from, or 1000?\n\n\nReturning to the broader topic of model selection\nModel selection works by choosing variables that seem to be the best at predicting the outcome. The more variables we have to choose from, the more likely it is we find one that predicts \\(Y\\) very well, even just by pure randomness, as the plots above show. In general, this model selection bias gets larger as the size of our “search space” increases – meaning not only number of variables, but also the complexity of the fitted relationships (e.g. non-linear). And in general, significance tests for the coefficients in the selected model will be biased toward smaller \\(p\\)-values, potentially causing us to commit more Type 1 errors.\nThis is part of the reason why scientists are sometimes unable to reproduce their own experiments. When they got a significant result (\\(p < 0.05\\)) the first time, it may have been due to model selection bias. When they try to reproduce the result, the noise just goes in a different direction, and their original result disappears."
  },
  {
    "objectID": "posts/2020-12-22-model-selection-bias-invalidates-significance-tests/model-selection-bias-invalidates-significance-tests.html#selection-bias-can-make-noise-look-like-signal",
    "href": "posts/2020-12-22-model-selection-bias-invalidates-significance-tests/model-selection-bias-invalidates-significance-tests.html#selection-bias-can-make-noise-look-like-signal",
    "title": "Model selection bias invalidates significance tests",
    "section": "Selection bias can make noise look like signal",
    "text": "Selection bias can make noise look like signal\nI hope you are convinced of this take home message. I began with a story about the candy dataset, instead of a simulation, because when people are analyzing their own data they never believe it might just be noise. The variables have names and meanings. When we see regression model output our first instinct may be to start interpreting the coefficients, becoming more confident about those that match our preconceptions and rationalizing about those that do not. But as we just saw, model selection makes it possible, and maybe even likely, to get nice looking significance test results even if the outcome variable is just pure noise.\nIn the candy example the outcome variable was noise, but that’s not essential. We could have had a real outcome variable but our predictor variables are all noise. Or we could have a mixture of real signals and noise. As long as there’s many variables, searching among them for the best makes the significant test results biased toward small \\(p\\)-values.\nIn future posts, I’ll describe three approaches to fixing this problem, including one that I’ve worked on in my own research."
  },
  {
    "objectID": "posts/welcome/welcome.html",
    "href": "posts/welcome/welcome.html",
    "title": "Relocating and rebuilding",
    "section": "",
    "text": "I’m also relocating to start a position in the Statistics Department at the London School of Economics. I’ll be teaching an undergraduate course on machine learning for statistics majors, and will post some of the materials in the teaching section here.\nA lot of things happened in 2020 and changed my thinking in certain ways. Imagining counterfactual responses and trajectories of the coronavirus pandemic is illuminating. From the beginning, and even now after almost a year, many countries have failed almost completely at learning from the experiences of others. There are deep structural, institutional, and behavioral obstacles to coordinated intentional action, which become worse the longer capitalism has dominated a given society. Thinking of economies as a distributed artificial intelligence, capitalism is a kind of overfitting- maximizing the wealth and power of one small class of people at the expense of every other possible fitness metric. We’ve seen myriad negative consequences of that this year in a kind of speed-run preview of what will likely become much worse over the course of climate change.\nI read a few books this year that influenced my thinking a lot.\nThis Life by Martin Hägglund resonated with vague but deeply held feelings I’ve had as long as I can remember, and gives a coherent way to think explicitly about them. My own short version: the fact of inevitable death reminds us that time is precious, but if we look around it seems most of us are “wasting” a lot of our time or “spending” it in ways we would rather not, which is a great tragedy and maybe the most important moral problem facing humanity. Hägglund argues convincingly to define democratic socialism as nothing less than a revolution in values which is required for humanity to be meaningfully free.\nThe Secret of Our Success by Joseph Henrich was my first in-depth exposure to academic research about (cumulative) cultural evolution. The book is focused on the particular ways that humans are different from other animals. I’m obsessed with cumulative cultural evolution now, even if I did disagree with the book in some points (mainly where it seems to take evolutionary psychology seriously for some reason). I’m somewhat convinced now that “over-imitation” is our One Weird Trick for building civilization, a useful lens through which to approach learning (and, therefore, anything that can be learned), and (despite this paper) closely related to another useful concept called “causal opacity.”\nLeaving New York was not easy. I’m gonna miss it. There are so many places I need to visit again when I get chance. With vaccines rolling out now, hopefully it won’t be long until we’re all visiting each other much more often again.\n\n\n\nMap showing the area around Washington Square Park"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Causal models for fairness\nThis work approaches fair machine learning from a causal inference perspective, arguing that determining what is fair is a similar challenge to determining causality. See our Nature Comment for a high level overview.\n\nPublications\n\nL. E. J. Bynum, J. R. Loftus, J. Stoyanovich, Counterfactuals for the Future. Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence, (AAAI 2023, to appear). [link]\nL. E. J. Bynum, J. R. Loftus, J. Stoyanovich, Disaggregated Interventions to Reduce Inequality. Equity and Access in Algorithms, Mechanisms, and Optimization, (EAAMO 2021). [link]\nK. Yang, J. R. Loftus, J. Stoyanovich, Causal intersectionality and fair ranking. Foundations of Responsible Computing, (FORC 2021). [link]\nM. J. Kusner, C. Russell, J. R. Loftus, R. Silva. Making Decisions that Reduce Discriminatory Impact. International Conference on Machine Learning, (ICML 2019). [link]\nM. J. Kusner, J. R. Loftus, C. Russell, R. Silva. Counterfactual fairness. Advances in Neural Information Processing Systems, (NeurIPS 2017). [link]\nC. Russell, M. J. Kusner, J. R. Loftus, R. Silva. When worlds collide: integrating different counterfactual assumptions in fairness. Advances in Neural Information Processing Systems, (NeurIPS 2017). [link]\nJ. R. Loftus, C. Russell, M. J. Kusner, R. Silva. Causal reasoning for algorithmic fairness. Preprint.\n\n\n\n\nPost-selection inference\nThis work involves challenging mathematical and computational aspects of conducting inference after model selection procedures with complicated underlying geometry. This enables significance testing, for example, after using some of the most popular model selection procedures such as the lasso with regularization chosen by cross-validation, or forward stepwise with number of steps chosen by AIC or BIC. Often the resulting significance tests are slightly modified versions of the classical tests in regression analysis. This blog post introduces the basic idea.\n\nSoftware\nI’m a co-author of the selectiveInference package on CRAN.\n\n\nPublications\n\nX. Tian, J. R. Loftus, J. E. Taylor. Selective inference with unknown variance via the square-root LASSO. Biometrika, 2018. [link]\nJ. E. Taylor, J. R. Loftus, and R. J. Tibshirani. Inference in adaptive regression via the Kac-Rice formula. Annals of Statistics, 2016. [link]\nJ. R. Loftus. Selective inference after cross-validation. Preprint.\nJ. R. Loftus and J. E. Taylor. Selective inference in regression models with groups of variables. Preprint.\nJ. R. Loftus, J. E. Taylor. A significance test for forward stepwise model selection. Preprint.\n\n\n\n\nCollaborations\n\nXu, J., et al. Landscape of monoallelic DNA accessibility in mouse embryonic stem cells and neural progenitor cells. Nature Genetics, 2017. [link]"
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "selectiveInference: Tools for Post-Selection Inference\nunbiasedgoodness: Goodness-of-Fit Tests After Model Selection"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks",
    "section": "",
    "text": "Recent talks\n\n\n\n\nPsychometric Society keynote\n\n\nDiscussion of Sani, Malinsky, and Shpitser [video]\n\n\nDiscussion of Panigrahi, MacDonald, and Kessler [video]\n\n\nWorkshop on Race and Racism in Science\n\n\nConference on Machine Learning and Inequality [video]"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Guide\nCourse website\n\n\n\nST310\nMachine Learning for Data Science\n\n\n\nST313\nEthics for Data Science\n\n\n\n\nStatistics for Data Science"
  }
]