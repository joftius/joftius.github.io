<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Causal interpretability and fairness</title>
    <meta charset="utf-8" />
    <meta name="author" content="Joshua Loftus (LSE Statistics)" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/ninjutsu.css" rel="stylesheet" />
    <script src="libs/htmlwidgets/htmlwidgets.js"></script>
    <script src="libs/d3/d3.min.js"></script>
    <script src="libs/dagre/dagre-d3.min.js"></script>
    <link href="libs/mermaid/dist/mermaid.css" rel="stylesheet" />
    <script src="libs/mermaid/dist/mermaid.slim.min.js"></script>
    <link href="libs/DiagrammeR-styles/styles.css" rel="stylesheet" />
    <script src="libs/chromatography/chromatography.js"></script>
    <script src="libs/DiagrammeR-binding/DiagrammeR.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="extra.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: bottom, left, title-slide

.title[
# Causal interpretability and fairness
]
.subtitle[
## Slides: joshualoftus.com/talks.html
]
.author[
### Joshua Loftus (LSE Statistics)
]

---


class: split-four









&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 1.2rem;
    padding: 1em 4em 1em 4em;
}
&lt;/style&gt;




.column[
![](matt.png)
Matt Kusner (UCL)
&amp;nbsp; 

&amp;nbsp; 

![](julia.png)
Julia Stoyanovich (NYU)
]

.column[
![](chris.png)
Chris Russell (AWS/ELLIS)

&amp;nbsp; 

![](ke.jpg)
Ke Yang (UMass)
]

.column[
![](ricardo.png)

Ricardo Silva (UCL)

&amp;nbsp;  

![](lucius.png)
Lucius Bynum (NYU)
]

.column[


![](sakina.jpg)
Sakina Hansen (LSE)

]

---

class: center, middle

# Causal fairness

---

### Origin story of my research

**Weapons of Math Destruction** by Cathy O'Neil

[ProPublica](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm):

![](../compas.png)



---

### AI and healthcare patient data

.pull-left[

![](obermeyer.png)

]
.pull-right[

[Obermeyer et al (2019)](https://science.sciencemag.org/content/366/6464/447.editor-summary)

- Algorithm assigns risk scores by **predicting healthcare costs** from patient records
- Underestimates risk of health conditions for black patients compared to white patients
- **Adjusting algorithm** to close the gap results in ~2.5x black patients receiving more care

]


---

### Serious business

.pull-left[
"New products and services, including those that incorporate or utilize **artificial intelligence and machine learning**, can raise new or exacerbate existing *ethical, technological, legal*, and other challenges, which **may negatively affect our brands** and demand for our products and services and **adversely affect our revenues** and operating results"
]
.pull-right[
![](../dumb.png)

Source: [WIRED](https://www.wired.com/story/google-microsoft-warn-ai-may-do-dumb-things/), Feb. 2019.

]

---

### Back in 2016

I thought: seems like this is about **causality**?

The "effect" of one variable, possibly "controlling for" others

Holland: **no causation without manipulation**


What can we manipulate?

---

.small[
**Are Emily and Greg More Employable than Lakisha and Jamal?** (Bertrand and Mullainathan, 2003)

Whitened Resumes: Race and Self-Presentation in the Labor Market (Kang et al, 2016)

*Systemic Discrimination Among Large U.S. Employers* (Kline et al, 2022)
]

![](https://hbswk.hbs.edu/PublishingImages/whitened-resumes.png)

---

Randomize (or blind) the **perception** of a sensitive variable (e.g. race) at one (late?) time point

![](darkness.png)




---

### Berkeley graduate admissions example

&gt; The bias in the aggregated data stems **not from any pattern of discrimination on the part of admissions committees**, which seem quite fair on the whole, but apparently from **prior screening at earlier levels** of the educational system. Women are shunted by their **socialization and education** toward fields of graduate study that are generally more crowded, less productive of completed degrees, and less well funded, and that frequently offer poorer professional employment prospects.

From the final paragraph of Bickel et al (1975)

#### What information / covariates should we condition on?

---

### Directed Acyclic Graph (DAG) models

![](berkeley.png)

- Assumption: paths show conditional dependence
- Assumption: intervention to change one variable also affects all variables on paths away from it


---

### Race and genomics in healthcare

We've heard about biased samples in health research

Different risk: a similar problem underlying [racist applications](https://www.nature.com/articles/d41586-018-06784-5) of behavioral genomics

.pull-left[
<div id="htmlwidget-6c364a5353b66148ae0c" style="width:504px;height:504px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-6c364a5353b66148ae0c">{"x":{"diagram":"\ngraph LR\n  R-->Y\n  S-->Y\n  R-->G\n"},"evals":[],"jsHooks":[]}</script>
]
.pull-right[
Race `\(R\)`, structural racism `\(S\)`, health outcome `\(Y\)`, polygenic score `\(G\)`

Higher dimensional `\(G\)` + more complex models = predicting `\(Y\)` without knowing why
]

---

### Healthcare recap

- **Optimizing for the wrong thing**: price signals aggregate a lot of social information, possibly including lack of access, poverty, etc. Also an **opacity** issue because we generally don't know all these influences on observed demand/spending

- **Sampling bias**: differential access to healthcare

- **Dimensionality and causation**: we have far more (high-dimensional) genomic data now than socio-economic/environment data


---

### (Infamous?) policing example

"Algorithm does not *explicitly* use race" -- in an unfair world, **other things can correlate with race**, e.g. prior convictions

.pull-left[
<div id="htmlwidget-043e8219f36d90c0ad2f" style="width:504px;height:504px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-043e8219f36d90c0ad2f">{"x":{"diagram":"\ngraph LR\n  R-->M\n  S-->M\n  S-->P\n  M-->P\n  P-->C\n"},"evals":[],"jsHooks":[]}</script>
]

.pull-right[
Race `\(R\)`, structural racism `\(S\)`, arrested for marijuana `\(M\)`, prior conviction `\(P\)`, risk score `\(C\)`

If `\(C\)` is computed using only `\(P\)` (and not `\(R\)` *directly*), is that "fair"?
]

---

### Fairness focused on one (later?) stage

- *perception* of race/gender
- balance *among applicants*

#### does not fix unfairness that occurred earlier

**Counterfactuals** help us think about this. **Depth** of the counterfactual story (starting earlier in time and/or length of causal pathway) corresponds to more/less fairness

VanderWeele and Robinson, 2015:

&gt; ... we tried to [...] provide a causal interpretation of the race coefficient in regression models that would be palatable to someone who was opposed to discussing causal effects for non-manipulable variables.



---

## Defining fairness causally

Kusner, Loftus, Russell, Silva. *Counterfactual fairness* ([NeurIPS 2017](https://papers.nips.cc/paper/2017/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html)):

Given a DAG, the predictor `\(\hat Y\)` is **counterfactually fair** if

`$$P(\hat Y_a | x, a) = P(\hat Y_{a'} |x, a)$$`



#### Proposition (sufficient, not necessary):
Any predictor `\(\hat Y\)` which is a function of only non-descendents of `\(A\)` in the DAG is counterfactually fair


---

### Pathway analysis / decomposition

.pull-left[

![](../nabi.png)

- [Kilbertus et al (2017)](https://papers.nips.cc/paper/2017/hash/f5f8590cd58a54e94377e6ae2eded4d9-Abstract.html): proxies and **resolving variables**

]


.pull-right[
- [Kusner et al (2017)](https://papers.nips.cc/paper/2017/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html): path-dependent counterfactual fairness (see supplement)
- [Zhang et al (2017)](https://www.ijcai.org/proceedings/2017/549)
- [Nabi and Shpitser (2018)](https://ojs.aaai.org/index.php/AAAI/article/view/11553)
- [Zhang and Bareinboim (2018)](https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16949/0)
- [Chiappa (2019)](https://ojs.aaai.org//index.php/AAAI/article/view/4777)
- ...

]


---

### At some point we must decide

#### Which version of fairness to achieve?

**(Simplified) impossibility theorem** see, e.g.: Kleinberg et al (2016), Chouldechova (2016) 

&gt; Unless the world is already fair, the only solutions satisfying both equal treatment (or opportunity) and equal outcomes (demographic parity) are trivial ones (e.g. jail everyone)


---

### At some point we must decide

#### Which causal model reveals our beliefs?

[George Box](https://en.wikipedia.org/wiki/George_E._P._Box):


&gt; [All models are wrong](All_models_are_wrong) but some are useful

therefore,

&gt; ... the scientist must be alert to what is **importantly wrong**

&gt; ... **cannot obtain a "correct" one** by excessive elaboration


---
class: split-four

### Every DAG is (importantly?) wrong

.column[
&amp;nbsp; 

<div id="htmlwidget-87d27f77d181add52336" style="width:504px;height:504px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-87d27f77d181add52336">{"x":{"diagram":"\ngraph TB\n  Race-->Outcome\n"},"evals":[],"jsHooks":[]}</script>
]
.column[
&amp;nbsp; 

<div id="htmlwidget-efc34d3c4a2c8f987aa3" style="width:504px;height:504px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-efc34d3c4a2c8f987aa3">{"x":{"diagram":"\ngraph TB\n  Racism-->Outcome\n"},"evals":[],"jsHooks":[]}</script>
]

.column[
&amp;nbsp; 


<div id="htmlwidget-c45adeeb1a8168e95f2d" style="width:504px;height:504px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-c45adeeb1a8168e95f2d">{"x":{"diagram":"\ngraph TB\n  A-->X\n  X-->Y\n  A-->Y\n"},"evals":[],"jsHooks":[]}</script>
]
.column[
&amp;nbsp; 

<div id="htmlwidget-56d3c5c4d2f291e17054" style="width:504px;height:504px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-56d3c5c4d2f291e17054">{"x":{"diagram":"\ngraph TB\n  A-->X\n  A-->R\n  X-->Y\n  R-->Y\n  A-->Y\n"},"evals":[],"jsHooks":[]}</script>
]

&amp;nbsp;

&amp;nbsp;

&amp;nbsp;

&amp;nbsp;

&amp;nbsp;

&amp;nbsp;


**Transparency**: we can say specifically what we disagree on

**Interpretation**: meanings of variables, edges (mechanisms)



---

## [Intersectional](https://en.wikipedia.org/wiki/Intersectionality) fairness

*Causal Intersectionality and Fair Ranking* (Yang, Stoyanovich, Loftus, [FORC 2021](https://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16187))

- Multiple sensitive attributes, e.g. race and gender

- Variety of relationships with other mediating variables

- Some of these mediators may be resolving/non-resolving for different sensitive attributes

Lots of scholarship, not much using formal mathematical models. See [Bright et al (2016)](https://www.journals.uchicago.edu/doi/abs/10.1086/684173), 
[O'Connor et al (2019)](https://www.tandfonline.com/doi/abs/10.1080/02691728.2018.1555870), and a few other references in our paper


---

## "Moving company" example

.pull-left[
Race, gender, weightlifting test, application score
<div id="htmlwidget-e65359df2667c90ad47a" style="width:504px;height:504px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-e65359df2667c90ad47a">{"x":{"diagram":"\ngraph TB\n  R-->X\n  G-->X\n  R-->Y\n  X-->Y\n  G-->Y\n"},"evals":[],"jsHooks":[]}</script>
]
.pull-right[
Weightlifting considered a **resolving variable** (company argues it is a necessary qualification)

&lt;img src="../moving.png" width="100%" style="display: block; margin: auto;" /&gt;

(See paper for results)
]


---

### Untangling intersectional relationships

*Race as a Bundle of Sticks* (Sen and Wasow, 2016)

Causal mediation with **multiple mediators** and **multiple causes** is a hard problem, limiting realistic application until better methods/data are available

![](../fig2.png)


---

class: center, middle

# Causal interpretability

---

### Classic methods (context/comparison)

#### Decision trees (recall: vaccine eligibility)

- If `Age &gt;= 40` then `yes`, otherwise `continue`
- If `HighRisk == TRUE` then `yes`, otherwise `continue`
- If `Job == CareWorker` then `yes`, otherwise `no`

#### Regression

- Predictor variables in the dataset: `\(x_1, x_2, \ldots, x_p\)`
- Coefficients/**parameters**, unknown: `\(\beta_1, \beta_2, \ldots, \beta_p\)`
- Outcome variable, also in data: `\(y\)`
- Algorithm inputs the data, outputs: estimated parameters, predictions of `\(y\)` using "recipe" or "weighted" combination

$$
\beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p
$$

---

## Transparent models

Understand how the model uses `\(x_1\)` to make a prediction...

## Opaque or black-box models

Internal model structure is hidden, or complicated enough to be difficult to understand

### xAI / IML

Tools to help human understanding of models

Usually focused on input-output

---

## Model-agnostic interpretability

If we can only access the input-output interface (e.g. external auditing of a proprietary model)

Does this black-box model discriminate? How does it depend on age?

Various IML tools: variable importance, partial dependence plots, local surrogates, "counterfactual" explanations (misnamed)

**Problem**: What do we mean by "depend" in "how does the output depend on a given input?"

e.g. proxies for sensitive attributes

---

## Causal interpretability

- *Causal Interpretations of Black-Box Models* (Zhao and Hastie, 2019)

Conditions under which a particular IML tool (PDP/ICE plots) can give valid causal conclusions

- *Causal Dependence Plots for Interpretable Machine Learning* (Loftus, Bynum, Hansen, 2023 [preprint](https://arxiv.org/abs/2303.04209))

---

![](../CDP.jpg)

---

class: center, middle

# Concluding

---

### Exciting advances in causal modeling

Observational data, double machine learning, causal reinforcement learning, ...

### Applications in ethical data science

Prioritizing normative values: fairness, privacy, interpretability, replicability, "alignment," ...


---

### Bet on causality

Claim: **causality** points us in good directions for research

- Choosing which covariates to condition on in fair prediction/decisions
- Changing focus from prediction to action, interventions, policy design, etc
- Making models/assumptions transparent

Deirdre Mulligan at (NeurIPS 2022) causal fairness workshop:

&gt; the important role [causal models] can play in supporting **collaborative reasoning about contested concepts, facilitating stakeholder participation** in decisions about how to meet policy goals within technical systems

---

### Parting wisdom (hard won, not by me)

Remember pragmatism, Box's rule: what's **important**? what's **useful**? (to who?)



### Thank you for listening!

Reading for a fairly general audience: The long road to fairer algorithms ([Nature, 2020](https://www.nature.com/articles/d41586-020-00274-3))

[joshualoftus.com](joshualoftus.com) slides and other info

---

Additional slides for question/discussion


---

### Impossibility: competing DAGs / pathways

*When Worlds Collide: Integrating Different Counterfactual Assumptions in Fairness* (Russell et al, [NeurIPS 2017](https://papers.nips.cc/paper/2017/hash/1271a7029c9df08643b631b02cf9e116-Abstract.html))

- Approximate counterfactual fairness (relax equality constraint)
- Approximately satisfy fairness across both (all) models
- Limitation: the more contradictory are the competing models, the more trivial the predictions (constant)
- Causal framing of fundamental contradiction

#### Resolving the contradiction
I think this is a good *path*. It's now about understanding the causes of unfairness well enough to reach consensus.


---

## Interventions under [interference](https://en.wikipedia.org/wiki/Spillover_(experiment%29)

&gt; Various models have only predicted the world in various ways. The point, however, is to change it

*Making Decisions that Reduce Discriminatory Impacts* (Kusner et al [ICML 2019](http://proceedings.mlr.press/v97/kusner19a.html))

- Designing an optimal policy / intervention / allocation 

- Relaxing common assumption that intervention on individual/unit `\(i\)` does not effect other individuals/units (in fairness/justice applications that will often be **importantly wrong**)

- Constraint: bound **counterfactual privilege**, preventing "rich get richer" effect

---

### Optimal fair policies (under interference)

.pull-left[
Intervention `\(\mathbf Z\)` trying to increase `\(\mathbf Y\)`

Privilege constraint, for `\(\tau \geq 0\)`
$$
\mathbb{E}[\mathbf{\hat Y}({\color{red}a},\mathbf{Z})] - \mathbb{E}[\mathbf{\hat Y}({\color{blue}a'},\mathbf{Z})] \leq \tau
$$
]
.pull-right[
![](../interference.png)
]

Optimization problem (with budget constraint `\(b\)`)

`$$\mathbf{Z} = \arg \max \sum_i \mathbb{E}\left[\mathbf{\hat Y}^{(i)}(a^{(i)}, \mathbf Z) | \mathbf A^{(i)}, \mathbf X^{(i)}  \right]$$`

`$$\quad s.t. \quad \sum_i \mathbf{Z}^{(i)} \leq b$$`
---

### Allocating resources to (NYC) schools

.pull-left[
Without constraint
![](../unfairschools.png)
]
.pull-right[
With constraint
![](../fairschools.png)
]

(See paper for discussion of results)

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"highlightSpans": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
(function(time) {
  var d2 = function(number) {
    return ('0' + number).slice(-2); // left-pad 0 to minutes/seconds
  },

  time_format = function(total) {
    var secs = Math.abs(total) / 1000;
    var h = Math.floor(secs / 3600);
    var m = Math.floor(secs % 3600 / 60);
    var s = Math.round(secs % 60);
    var res = d2(m) + ':' + d2(s);
    if (h > 0) res = h + ':' + res;
    return res;  // [hh:]mm:ss
  },

  slide_number_div = function(i) {
    return document.getElementsByClassName('remark-slide-number').item(i);
  },

  current_page_number = function(i) {
    return slide_number_div(i).firstChild.textContent;  // text "i / N"
  };

  var timer = document.createElement('span'); timer.id = 'slide-time-left';
  var time_left = time, k = slideshow.getCurrentSlideIndex(),
      last_page_number = current_page_number(k);

  setInterval(function() {
    time_left = time_left - 1000;
    timer.innerHTML = ' ' + time_format(time_left);
    if (time_left < 0) timer.style.color = 'red';
  }, 1000);

  slide_number_div(k).appendChild(timer);

  slideshow.on('showSlide', function(slide) {
    var i = slide.getSlideIndex(), n = current_page_number(i);
    // reset timer when a new slide is shown and the page number is changed
    if (last_page_number !== n) {
      time_left = time; last_page_number = n;
      timer.innerHTML = ' ' + time_format(time); timer.style.color = null;
    }
    slide_number_div(i).appendChild(timer);
  });
})(59000);
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
