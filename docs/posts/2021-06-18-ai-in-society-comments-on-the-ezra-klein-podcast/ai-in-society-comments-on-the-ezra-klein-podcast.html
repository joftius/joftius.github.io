<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Joshua Loftus">
<meta name="dcterms.date" content="2021-06-18">
<meta name="description" content="Tech utopianism, liberal fears, and challenging monopoly/power with democratic socialism">

<title> joshua loftus - AI in society: comments on the Ezra Klein podcast</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-114292497-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Joshua Loftus: Statistician and Data Scientist">
<meta property="og:description" content="Tech utopianism, liberal fears, and challenging monopoly/power with democratic socialism">
<meta property="og:site-name" content="{{< fa solid chart-simple size=large >}} joshua loftus">
<meta name="twitter:title" content="Joshua Loftus: Statistician and Data Scientist">
<meta name="twitter:description" content="Tech utopianism, liberal fears, and challenging monopoly/power with democratic socialism">
<meta name="twitter:creator" content="@joftius">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title"><i class="fa-solid fa-chart-simple fa-large" aria-hidden="true"></i> joshua loftus</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"><i class="fa-solid fa-house fa-large" aria-hidden="true"></i> home</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../research.html"><i class="fa-solid fa-book-open fa-large" aria-hidden="true"></i> research</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../teaching.html"><i class="fa-solid fa-chalkboard fa-large" aria-hidden="true"></i> teaching</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../software.html"><i class="fa-solid fa-code fa-large" aria-hidden="true"></i> software</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html"><i class="fa-solid fa-comment fa-large" aria-hidden="true"></i> blog</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"><i class="fa-solid fa-user fa-large" aria-hidden="true"></i> about</a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">AI in society: comments on the Ezra Klein podcast</h1>
                  <div>
        <div class="description">
          <p>Tech utopianism, liberal fears, and challenging monopoly/power with democratic socialism</p>
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Joshua Loftus </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 18, 2021</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="power-and-control" class="level2">
<h2 class="anchored" data-anchor-id="power-and-control">Power and control</h2>
<p>I’ll begin where I’m in agreement with Ezra and some of his guests. <a href="https://www.nytimes.com/2021/03/30/opinion/ezra-klein-podcast-ted-chiang.html?showTranscript=1">Ted Chiang</a> put it well:</p>
<blockquote class="blockquote">
<p><strong>I tend to think that most fears about A.I. are best understood as fears about capitalism</strong>. And I think that this is actually true of most fears of technology, too. Most of our fears or anxieties about technology are best understood as fears or anxiety about how capitalism will use technology against us. And technology and capitalism have been so closely intertwined that it’s hard to distinguish the two.</p>
</blockquote>
<p>This is an important insight that I would modify only slightly. Even though I am personally a democratic socialist, I think it’s too specific to place the blame or fear entirely on capitalism. It’s important to ask who is in control and who has power, and “capitalists” is one good and highly explanatory answer to that question- but it’s not the only answer. I’m also afraid of the possibility <em>nobody is in control</em>, that the feedback loops between homo sapiens and its tools and culture that have already wreaked so much havoc on the planet are only going to continue their devastating expansion. And even in my ideal scenario–where all of humanity is actively engaged in democratic control, education, use, and creation of technology–<strong>there will always be political struggles and contradictions, and technology/“AI” will be both subject of and tool in those struggles</strong>.</p>
<p>Chiang was careful to say “most,” so he is probably right.</p>
</section>
<section id="algorithms-have-no-agency" class="level2">
<h2 class="anchored" data-anchor-id="algorithms-have-no-agency">Algorithms have no agency</h2>
<p>This is such a basic point, but I think it’s worth stressing and repeating because it is so often forgotten, especially in conversations about AI: <strong>just because “intelligence” is in the name does not mean the thing is intelligent</strong>.</p>
<p>It’s an <a href="https://twitter.com/ben_golub/status/1403776416051830788">open secret</a> that the discipline of Computer Science has a knack for giving things cool names because this makes <a href="https://twitter.com/daniela_witten/status/1177330096530579456">raising money</a> easier. But this becomes a problem when people start uncritically believing the marketing copy, and the problem compounds when uncritical views are passed on to generations of impressionable students–some of whom may drop out of school to become tech CEOs without ever doing the homework of calculating some examples by hand and <em>viscerally</em> understanding the infinite dullness of the underlying mechanisms. It’s glorified bookkeeping.</p>
<p><a href="https://en.wikipedia.org/wiki/Agent-based_model">“Agent-based” computing</a> and <a href="https://en.wikipedia.org/wiki/Evolutionary_algorithm">“evolutionary” algorithms</a> and deep <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">“neural” networks</a> are <em>names</em> for computational tools. Tools do not have agency, they are objects that actual agents use for their own purposes. If you don’t believe an <a href="https://en.wikipedia.org/wiki/Abacus">abacus</a> makes decisions then you should not believe that an <em>electric-powered abacus</em> makes decisions, and that’s basically all that a computer is or ever will be. A complicated abacus that can convert a picture into numbers, do mathematical operations on those numbers, and convert the result into another picture… is not a living organism. This is true even if the output pictures are recognizable and meaningful to the living organisms using the machine. And it remains true even if thousands or millions of actual living organisms collectively work to “train” the machinery in the abacus to produce interesting input-output combinations. <em>It is still a lifeless machine</em>.</p>
<p>Works of art did not become sentient because painters learned good enough realism techniques to trick us into thinking we’re looking at a photograph.</p>
<section id="so-dont-feel-sorry-for-them" class="level3">
<h3 class="anchored" data-anchor-id="so-dont-feel-sorry-for-them">So don’t feel sorry for them</h3>
<p>Klein has been repeating Chiang’s concern to the effect that, I paraphrase: “long before we create AGI we will create <em>beings capable of suffering</em>, and given our track record on animal welfare this would likely become a horrific moral atrocity of mass suffering.” No.&nbsp;Stop. We don’t need to <a href="https://thereader.mitpress.mit.edu/2020-the-year-of-robot-rights/">imagine</a> the suffering of some science fictional entities. There are enough actual living beings, including actual humans, who are already suffering and whose real plights demand our attention now. We can empathize with fictional characters to enjoy a good story, but at some point we have to close the book or turn off the screen and attend to real life.</p>
</section>
<section id="and-dont-forget-who-is-in-charge" class="level3">
<h3 class="anchored" data-anchor-id="and-dont-forget-who-is-in-charge">And don’t forget who is in charge</h3>
<p>Algorithms only ever do what they have been instructed to do. It’s a false distinction–again just marketing copy–to say that AI or machine learning are a new kind of programming which is different from the old “rules based” paradigm. They take “training data” as an input? So do the algorithms that calculate a simple mean or a regression line. So does a sextant. If a computer language has abstractions that allow the programmer to write shorter and more human-readable code that does not mean that the <em>computer</em> has become more intelligent. (Matlab is not a paradigm shift relative to C because it has a simpler notation for doing matrix multiplication). If the output of a program is surprising to the engineers who designed it, that’s just <em>bad engineering</em> (and potentially unsafe when used in the real world); it’s a bug, not a feature.</p>
<p>I will probably have to make this point over and over forever because there’s a massive industry profiting from the misconception. It’s humans who have the agency. The simulacrum of intelligence we might perceive in the output of a computer program is just an echo of the actual intelligence of the humans who created the system, including its “training data.” It’s what David Donoho calls “<a href="https://hdsr.mitpress.mit.edu/pub/rim3pvdw/release/6">recycled intelligence</a>.”</p>
</section>
</section>
<section id="political-economy-of-agi" class="level2">
<h2 class="anchored" data-anchor-id="political-economy-of-agi">Political economy of AGI</h2>
<p>What’s the point of “general purpose” AI? Why try to make it? Klein asked the CEO of OpenAI:</p>
<blockquote class="blockquote">
<p>EZRA KLEIN: Why try to make it generally intelligent at all? Geoff Hinton, one of the fathers of neural networks, he had this quote in the book “Genius Makers,” that I recently read, where he just says, why do you want the robot digging your ditches to know about baseball? […] Why not just create narrow worker machine learning programs?</p>
<p>SAM ALTMAN: I have a lot of answers to this question, so I will start with a few. Number one, one thing that I really want is new knowledge creation. It is one thing to say you can have an A.I. that is as good as any human A.I. doctor. It is another to say you can have an A.I. that can solve all human disease in a way that humans are just not capable of doing. And I think you need a generally intelligent system to do that, to generate new knowledge, to learn new things, to do things humans can’t do. And it will need to pull together expertise across many different areas that no human is capable of holding in their brain at once — or even a team of humans — to do.</p>
<p>So what a depressing thought to say that we’re going to limit ourselves to what humans are capable of rather than benefit from everything that we can build better tools for. We build tools so that we can do better than we can do with our hands digging up the dirt or whatever. All of this, everything we have here is because we started digging up the ground, finding stuff. And we made this room. We made this microphone. We made the internet. We have done incredible work with tools that have let us shoot past what we’d be capable of without them. And let’s not stop. That would really be depressing to me.</p>
<p>Two is that someone’s going to do it. The upside of these systems are such that Geoff Hinton can certainly decide not to try to build generally intelligent systems, but someone’s going to do it. So I think there is no future that doesn’t have these systems in it. And so we have to talk about how we want to use them, what their rights are, what we want the world to look like, the universe to look like with them.</p>
</blockquote>
<p>I don’t believe this story. There are simpler explanations that are consistent with everything else we know about Silicon Valley in particular and post-industrial economics and politics in general. I’ll give my own explanation in the next section, but first I want to critique Altman’s views.</p>
<p>His first reason for building AGI is that it will do things humans are not capable of doing. He then goes on to point out how humanity has accomplished some great things by building and using tools. These are contradictory, because the first one is hiding the agency of the humans that would be <em>using</em> “AGI” as a tool to make great new discoveries or something. We don’t say things like “microscopes solved disease,” or</p>
<section id="fooling-all-the-people-all-the-time" class="level3">
<h3 class="anchored" data-anchor-id="fooling-all-the-people-all-the-time">Fooling all the people, all the time</h3>
<p>This is basically my definition for artificial general intelligence. We know it’s not an AGI if its recycled intelligence fails to fool us some of the time. It’s easier to create a customer service “chatbot” for a specific company because there are only a few topics that will cover most customers’ questions. So it’s easier to confuse or fool a customer into thinking they might be talking to a person rather than interacting with a glorified FAQ with built-in time delays for “typing.”</p>
<p>Consistent with my earlier point that algorithms and computers do not have agency or intelligence,</p>
</section>
<section id="agi-monopoly" class="level3">
<h3 class="anchored" data-anchor-id="agi-monopoly">AGI = monopoly</h3>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } 
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>